{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c95cc6-71fe-4a8b-82cf-9dcd2a0ec925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import pynvml\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths to the executables\n",
    "cuda_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\Lanczos Cuda\\Lanczos\\x64\\Debug\\Lanczos.exe\"\n",
    "openmp_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\OpenMP lanczos\\x64\\Debug\\OpenMP larczos.exe\"\n",
    "sequential_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\Sequential lanczos\\x64\\Debug\\Sequential lanczos.exe\"\n",
    "\n",
    "def truncate_values(values, decimals=2):\n",
    "    \"\"\"Truncates a list of float values to a specified number of decimals.\"\"\"\n",
    "    return [round(value, decimals) for value in values]\n",
    "\n",
    "def append_resolution_to_filename(filename, width, height):\n",
    "    \"\"\"Appends the resolution size to the output filename.\"\"\"\n",
    "    base, ext = filename.rsplit('.', 1)\n",
    "    return f\"{base}_{width}x{height}.{ext}\"\n",
    "\n",
    "def get_image_resolution(image_path):\n",
    "    \"\"\"Fetches the resolution of the input image.\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.width, img.height\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching resolution of {image_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_average(values):\n",
    "    \"\"\"Calculates the average of a list of values.\"\"\"\n",
    "    return sum(values) / len(values) if values else 0\n",
    "\n",
    "def main():\n",
    "    # Prompt user for input\n",
    "    input_image = input(\"Enter the input image filename: \").strip()\n",
    "    output_image_base = input(\"Enter the base output image filename (without prefix): \").strip()\n",
    "    scale_factor = input(\"Enter the scaling factor (positive number): \").strip()\n",
    "\n",
    "    try:\n",
    "        scale_factor = float(scale_factor)\n",
    "        if scale_factor <= 0:\n",
    "            raise ValueError(\"Scale factor must be positive.\")\n",
    "    except ValueError as e:\n",
    "        print(f\"Invalid scale factor: {e}\")\n",
    "        return\n",
    "\n",
    "    # Fetch resolution of the input image\n",
    "    original_width, original_height = get_image_resolution(input_image)\n",
    "    if original_width is None or original_height is None:\n",
    "        print(\"Could not fetch image resolution. Exiting.\")\n",
    "        return\n",
    "\n",
    "    scaled_width = int(original_width * scale_factor)\n",
    "    scaled_height = int(original_height * scale_factor)\n",
    "\n",
    "    # Construct output filenames by adding appropriate prefixes and resolution\n",
    "    output_image_cuda = append_resolution_to_filename(\n",
    "        os.path.join(os.path.dirname(output_image_base), \"cuda_\" + os.path.basename(output_image_base)),\n",
    "        scaled_width, scaled_height\n",
    "    )\n",
    "    output_image_openmp = append_resolution_to_filename(\n",
    "        os.path.join(os.path.dirname(output_image_base), \"openmp_\" + os.path.basename(output_image_base)),\n",
    "        scaled_width, scaled_height\n",
    "    )\n",
    "    output_image_sequential = append_resolution_to_filename(\n",
    "        os.path.join(os.path.dirname(output_image_base), \"sequential_\" + os.path.basename(output_image_base)),\n",
    "        scaled_width, scaled_height\n",
    "    )\n",
    "\n",
    "    # Run CUDA version\n",
    "    print(\"\\nRunning CUDA...\")\n",
    "    cuda_time, cuda_memory, cuda_core_max_usage, cuda_core_avg_usage, cuda_gpu_max, cuda_gpu_avg, cuda_stdout, cuda_stderr = run_program_with_metrics(cuda_exe_path, input_image, output_image_cuda, scale_factor)\n",
    "    if cuda_time is not None:\n",
    "        average_cuda_cpu = calculate_average(cuda_core_avg_usage)\n",
    "\n",
    "    # Run OpenMP version\n",
    "    print(\"Running OpenMP...\")\n",
    "    openmp_time, openmp_memory, openmp_core_max_usage, openmp_core_avg_usage, _, _, openmp_stdout, openmp_stderr = run_program_with_metrics(openmp_exe_path, input_image, output_image_openmp, scale_factor)\n",
    "    if openmp_time is not None:\n",
    "        average_openmp_cpu = calculate_average(openmp_core_avg_usage)\n",
    "\n",
    "    \n",
    "    # Run Sequential version\n",
    "    print(\"Running Sequential...\\n\")\n",
    "    sequential_time, sequential_memory, sequential_core_max_usage, sequential_core_avg_usage, _, _, sequential_stdout, sequential_stderr = run_program_with_metrics(sequential_exe_path, input_image, output_image_sequential, scale_factor)\n",
    "    if sequential_time is not None:\n",
    "        average_sequential_cpu = calculate_average(sequential_core_avg_usage)\n",
    "\n",
    "    # Section 1: CUDA vs Sequential\n",
    "    print(f\"File Name: {output_image_cuda}\")\n",
    "    print(f\"File Name: {output_image_sequential}\\n\")\n",
    "\n",
    "    print(f\"Sequential Execution Time   : {sequential_time:.4f} seconds\")\n",
    "    print(f\"Sequential Peak Memory Usage: {sequential_memory:.2f} MB\")\n",
    "    print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\\n\")\n",
    "\n",
    "    print(f\"CUDA Execution Time   : {cuda_time:.4f} seconds\")\n",
    "    print(f\"CUDA Peak Memory Usage: {cuda_memory:.2f} MB\")\n",
    "    print(f\"CUDA Average CPU Usage: {average_cuda_cpu:.2f} %\")\n",
    "    print(f\"CUDA Average GPU Usage: {cuda_gpu_avg:.2f} %\\n\")\n",
    "\n",
    "    print(\"Performance Evaluation\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Sequential Execution Time : {sequential_time:.4f}s\")\n",
    "    print(f\"CUDA Execution Time       : {cuda_time:.4f}s\")\n",
    "    print(f\"Speedup                   : {sequential_time - cuda_time:+.4f}s\\n\")\n",
    "\n",
    "    print(f\"Sequential Memory Usage   : {sequential_memory:.2f} MB\")\n",
    "    print(f\"CUDA Memory Usage         : {cuda_memory:.2f} MB\")\n",
    "    print(f\"Difference                : {sequential_memory - cuda_memory:+.2f} MB\\n\")\n",
    "\n",
    "    print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\")\n",
    "    print(f\"CUDA Average CPU Usage      : {average_cuda_cpu:.2f} %\")\n",
    "    print(f\"Difference                  : {average_sequential_cpu - average_cuda_cpu:+.2f} %\\n\")\n",
    "\n",
    "    # Section 2: OpenMP vs Sequential\n",
    "    print(f\"File Name: {output_image_openmp}\")\n",
    "    print(f\"File Name: {output_image_sequential}\\n\")\n",
    "\n",
    "    print(f\"Sequential Execution Time   : {sequential_time:.4f} seconds\")\n",
    "    print(f\"Sequential Peak Memory Usage: {sequential_memory:.2f} MB\")\n",
    "    print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\\n\")\n",
    "\n",
    "    print(f\"OpenMP Execution Time   : {openmp_time:.4f} seconds\")\n",
    "    print(f\"OpenMP Peak Memory Usage: {openmp_memory:.2f} MB\")\n",
    "    print(f\"OpenMP Average CPU Usage: {average_openmp_cpu:.2f} %\\n\")\n",
    "\n",
    "    print(\"Performance Evaluation\")\n",
    "    print(\"==========================\")\n",
    "    print(f\"Sequential Execution Time : {sequential_time:.4f}s\")\n",
    "    print(f\"OpenMP Execution Time     : {openmp_time:.4f}s\")\n",
    "    print(f\"Speedup                   : {sequential_time - openmp_time:+.4f}s\\n\")\n",
    "\n",
    "    print(f\"Sequential Memory Usage   : {sequential_memory:.2f} MB\")\n",
    "    print(f\"OpenMP Memory Usage       : {openmp_memory:.2f} MB\")\n",
    "    print(f\"Difference                : {sequential_memory - openmp_memory:+.2f} MB\\n\")\n",
    "\n",
    "    print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\")\n",
    "    print(f\"OpenMP Average CPU Usage    : {average_openmp_cpu:.2f} %\")\n",
    "    print(f\"Difference                  : {average_sequential_cpu - average_openmp_cpu:+.2f} %\\n\")\n",
    "\n",
    "    # Create bar chart for Sequential vs OpenMP execution time\n",
    "    fig_time_openmp = go.Figure()\n",
    "    fig_time_openmp.add_trace(go.Bar(x=[\"Sequential\", \"OpenMP\"], \n",
    "                                     y=[sequential_time, openmp_time], \n",
    "                                     name='Execution Time (s)', \n",
    "                                     marker_color=['blue', 'orange']))\n",
    "    fig_time_openmp.update_layout(\n",
    "        title=f'Sequential vs OpenMP Execution Time on {input_image}',\n",
    "        xaxis_title='Method',\n",
    "        yaxis_title='Time (seconds)',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_time_openmp.show()\n",
    "\n",
    "    # Create bar chart for Sequential vs OpenMP memory usage\n",
    "    fig_memory_openmp = go.Figure()\n",
    "    fig_memory_openmp.add_trace(go.Bar(x=[\"Sequential\", \"OpenMP\"], \n",
    "                                       y=[sequential_memory, openmp_memory], \n",
    "                                       name='Memory Usage (MB)', \n",
    "                                       marker_color=['blue', 'orange']))\n",
    "    fig_memory_openmp.update_layout(\n",
    "        title=f'Sequential vs OpenMP Memory Usage on {input_image}',\n",
    "        xaxis_title='Method',\n",
    "        yaxis_title='Memory (MB)',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_memory_openmp.show()\n",
    "\n",
    "    # Create bar chart for Sequential vs CUDA execution time\n",
    "    fig_time_cuda = go.Figure()\n",
    "    fig_time_cuda.add_trace(go.Bar(x=[\"Sequential\", \"CUDA\"], \n",
    "                                   y=[sequential_time, cuda_time], \n",
    "                                   name='Execution Time (s)', \n",
    "                                   marker_color=['blue', 'green']))\n",
    "    fig_time_cuda.update_layout(\n",
    "        title=f'Sequential vs CUDA Execution Time on {input_image}',\n",
    "        xaxis_title='Method',\n",
    "        yaxis_title='Time (seconds)',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_time_cuda.show()\n",
    "\n",
    "    # Create bar chart for Sequential vs CUDA memory usage\n",
    "    fig_memory_cuda = go.Figure()\n",
    "    fig_memory_cuda.add_trace(go.Bar(x=[\"Sequential\", \"CUDA\"], \n",
    "                                     y=[sequential_memory, cuda_memory], \n",
    "                                     name='Memory Usage (MB)', \n",
    "                                     marker_color=['blue', 'green']))\n",
    "    fig_memory_cuda.update_layout(\n",
    "        title=f'Sequential vs CUDA Memory Usage on {input_image}',\n",
    "        xaxis_title='Method',\n",
    "        yaxis_title='Memory (MB)',\n",
    "        template='plotly_dark'\n",
    "    )\n",
    "    fig_memory_cuda.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "_360p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd12d03-e7d1-4422-8756-7d49596669d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "import psutil\n",
    "import pynvml\n",
    "import plotly.graph_objects as go\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths to the executables\n",
    "cuda_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\Lanczos Cuda\\Lanczos\\x64\\Debug\\Lanczos.exe\"\n",
    "openmp_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\OpenMP lanczos\\x64\\Debug\\OpenMP larczos.exe\"\n",
    "sequential_exe_path = r\"C:\\Users\\user\\Desktop\\dspc\\Assignment\\Lanczos-Resampling\\Sequential lanczos\\x64\\Debug\\Sequential lanczos.exe\"\n",
    "\n",
    "# Initialize GPU monitoring (only needed for CUDA)\n",
    "def init_gpu_monitoring():\n",
    "    try:\n",
    "        pynvml.nvmlInit()\n",
    "        return pynvml.nvmlDeviceGetHandleByIndex(0)  # Assuming single GPU system\n",
    "    except pynvml.NVMLError as e:\n",
    "        print(f\"Error initializing GPU monitoring: {e}\")\n",
    "        return None\n",
    "\n",
    "gpu_handle = init_gpu_monitoring()\n",
    "\n",
    "def get_gpu_usage():\n",
    "    \"\"\"Returns GPU utilization percentage if available, otherwise None.\"\"\"\n",
    "    try:\n",
    "        if gpu_handle:\n",
    "            return pynvml.nvmlDeviceGetUtilizationRates(gpu_handle).gpu\n",
    "    except pynvml.NVMLError:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def run_program_with_metrics(exe_path, input_image, output_image, scale_factor):\n",
    "    \"\"\"Runs the executable with provided arguments and tracks memory, CPU (per-core), and GPU usage.\"\"\"\n",
    "    if not os.path.exists(input_image):\n",
    "        print(f\"Error: Input image not found at full path: {os.path.abspath(input_image)}\")\n",
    "        return None, None, None, None, None, None, None\n",
    "\n",
    "    max_memory = 0\n",
    "    max_cpu = 0\n",
    "    max_gpu = 0\n",
    "    cpu_samples = []\n",
    "    gpu_samples = []\n",
    "    num_cores = psutil.cpu_count(logical=True)  # Get the number of logical cores\n",
    "    per_core_max_usage = [0] * num_cores  # Initialize per-core max usage\n",
    "    per_core_sum_usage = [0] * num_cores  # Initialize per-core sum for average usage\n",
    "    num_samples = 0  # To track the number of CPU/GPU samples taken\n",
    "    start_time = time.time()\n",
    "\n",
    "    try:\n",
    "        # Start the process\n",
    "        process = subprocess.Popen(\n",
    "            [exe_path, input_image, output_image, str(scale_factor)],\n",
    "            stdout=subprocess.PIPE,\n",
    "            stderr=subprocess.PIPE,\n",
    "            text=True\n",
    "        )\n",
    "\n",
    "        # Use the process PID to track memory and CPU\n",
    "        proc = psutil.Process(process.pid)\n",
    "\n",
    "        # Monitor usage until the process completes\n",
    "        while process.poll() is None:  # Check if the process is still running\n",
    "            try:\n",
    "                # Memory usage\n",
    "                current_memory = proc.memory_info().rss / (1024 ** 2)  # Memory in MB\n",
    "                max_memory = max(max_memory, current_memory)\n",
    "\n",
    "                # CPU usage (per-core)\n",
    "                current_per_core_usage = psutil.cpu_percent(interval=0.1, percpu=True)\n",
    "                num_samples += 1\n",
    "                for i, usage in enumerate(current_per_core_usage):\n",
    "                    per_core_max_usage[i] = max(per_core_max_usage[i], usage)\n",
    "                    per_core_sum_usage[i] += usage\n",
    "\n",
    "                # GPU usage (if applicable)\n",
    "                if \"cuda\" in exe_path.lower():  # Only track GPU usage for CUDA\n",
    "                    current_gpu = get_gpu_usage()\n",
    "                    if current_gpu is not None:\n",
    "                        max_gpu = max(max_gpu, current_gpu)\n",
    "                        gpu_samples.append(current_gpu)\n",
    "\n",
    "            except psutil.NoSuchProcess:\n",
    "                break  # The process might have exited\n",
    "\n",
    "        # Compute average CPU usage per core\n",
    "        per_core_avg_usage = [usage / num_samples for usage in per_core_sum_usage]\n",
    "\n",
    "        # Compute average GPU usage (if applicable)\n",
    "        avg_gpu = sum(gpu_samples) / len(gpu_samples) if gpu_samples else None\n",
    "\n",
    "        # Collect the output and errors\n",
    "        stdout, stderr = process.communicate()\n",
    "        end_time = time.time()\n",
    "\n",
    "        return end_time - start_time, max_memory, per_core_max_usage, per_core_avg_usage, max_gpu, avg_gpu, stdout, stderr\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error running {exe_path}: {e}\")\n",
    "        return None, None, None, None, None, None, None, None\n",
    "\n",
    "def truncate_values(values, decimals=2):\n",
    "    \"\"\"Truncates a list of float values to a specified number of decimals.\"\"\"\n",
    "    return [round(value, decimals) for value in values]\n",
    "\n",
    "def append_resolution_to_filename(filename, width, height):\n",
    "    \"\"\"Appends the resolution size to the output filename.\"\"\"\n",
    "    base, ext = filename.rsplit('.', 1)\n",
    "    return f\"{base}_{width}x{height}.{ext}\"\n",
    "\n",
    "def get_image_resolution(image_path):\n",
    "    \"\"\"Fetches the resolution of the input image.\"\"\"\n",
    "    try:\n",
    "        with Image.open(image_path) as img:\n",
    "            return img.width, img.height\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching resolution of {image_path}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_average(values):\n",
    "    \"\"\"Calculates the average of a list of values.\"\"\"\n",
    "    return sum(values) / len(values) if values else 0\n",
    "\n",
    "def run_multiple_inputs(input_sets):\n",
    "    for idx, input_set in enumerate(input_sets, start=1):\n",
    "        input_image = input_set['input_image']\n",
    "        output_image_base = input_set['output_image_base']\n",
    "        scale_factor = input_set['scale_factor']\n",
    "\n",
    "        # Fetch resolution of the input image\n",
    "        original_width, original_height = get_image_resolution(input_image)\n",
    "        if original_width is None or original_height is None:\n",
    "            print(\"Could not fetch image resolution. Skipping this input.\")\n",
    "            continue\n",
    "\n",
    "        scaled_width = int(original_width * scale_factor)\n",
    "        scaled_height = int(original_height * scale_factor)\n",
    "\n",
    "        # Construct output filenames by adding appropriate prefixes and resolution\n",
    "        output_image_cuda = append_resolution_to_filename(\n",
    "            os.path.join(os.path.dirname(output_image_base), \"cuda_\" + os.path.basename(output_image_base)),\n",
    "            scaled_width, scaled_height\n",
    "        )\n",
    "        output_image_openmp = append_resolution_to_filename(\n",
    "            os.path.join(os.path.dirname(output_image_base), \"openmp_\" + os.path.basename(output_image_base)),\n",
    "            scaled_width, scaled_height\n",
    "        )\n",
    "        output_image_sequential = append_resolution_to_filename(\n",
    "            os.path.join(os.path.dirname(output_image_base), \"sequential_\" + os.path.basename(output_image_base)),\n",
    "            scaled_width, scaled_height\n",
    "        )\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Execution Set {idx}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        print(f\"Input image filename       : {input_image}\")\n",
    "        print(f\"Base output image filename : {output_image_base}\")\n",
    "        print(f\"Scaling factor             : {scale_factor}\")\n",
    "        print(f\"{'-'*80}\") \n",
    "        \n",
    "        # Run CUDA version\n",
    "        print(f\"\\nRunning CUDA for {input_image}...\")\n",
    "        cuda_time, cuda_memory, cuda_core_max_usage, cuda_core_avg_usage, cuda_gpu_max, cuda_gpu_avg, cuda_stdout, cuda_stderr = run_program_with_metrics(cuda_exe_path, input_image, output_image_cuda, scale_factor)\n",
    "        if cuda_time is not None:\n",
    "            average_cuda_cpu = calculate_average(cuda_core_avg_usage)\n",
    "\n",
    "        # Run OpenMP version\n",
    "        print(f\"Running OpenMP for {input_image}...\")\n",
    "        openmp_time, openmp_memory, openmp_core_max_usage, openmp_core_avg_usage, _, _, openmp_stdout, openmp_stderr = run_program_with_metrics(openmp_exe_path, input_image, output_image_openmp, scale_factor)\n",
    "        if openmp_time is not None:\n",
    "            average_openmp_cpu = calculate_average(openmp_core_avg_usage)\n",
    "\n",
    "        # Run Sequential version\n",
    "        print(f\"Running Sequential for {input_image}...\\n\")\n",
    "        sequential_time, sequential_memory, sequential_core_max_usage, sequential_core_avg_usage, _, _, sequential_stdout, sequential_stderr = run_program_with_metrics(sequential_exe_path, input_image, output_image_sequential, scale_factor)\n",
    "        if sequential_time is not None:\n",
    "            average_sequential_cpu = calculate_average(sequential_core_avg_usage)\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Results for {input_image} - CUDA VS Sequential\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        print(f\"Output file Name: {output_image_cuda}\")\n",
    "        print(f\"Output file Name: {output_image_sequential}\\n\")\n",
    "\n",
    "        print(f\"Sequential Execution Time   : {sequential_time:.4f} seconds\")\n",
    "        print(f\"Sequential Peak Memory Usage: {sequential_memory:.2f} MB\")\n",
    "        print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\\n\")\n",
    "\n",
    "        print(f\"CUDA Execution Time   : {cuda_time:.4f} seconds\")\n",
    "        print(f\"CUDA Peak Memory Usage: {cuda_memory:.2f} MB\")\n",
    "        print(f\"CUDA Average CPU Usage: {average_cuda_cpu:.2f} %\")\n",
    "        print(f\"CUDA Average GPU Usage: {cuda_gpu_avg:.2f} %\\n\")\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Performance Evaluation - CUDA VS Sequential\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Sequential Execution Time : {sequential_time:.4f}s\")\n",
    "        print(f\"CUDA Execution Time       : {cuda_time:.4f}s\")\n",
    "        print(f\"Speedup                   : {sequential_time - cuda_time:+.4f}s\\n\")\n",
    "\n",
    "        print(f\"Sequential Memory Usage   : {sequential_memory:.2f} MB\")\n",
    "        print(f\"CUDA Memory Usage         : {cuda_memory:.2f} MB\")\n",
    "        print(f\"Difference                : {sequential_memory - cuda_memory:+.2f} MB\\n\")\n",
    "\n",
    "        print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\")\n",
    "        print(f\"CUDA Average CPU Usage      : {average_cuda_cpu:.2f} %\")\n",
    "        print(f\"Difference                  : {average_sequential_cpu - average_cuda_cpu:+.2f} %\\n\")\n",
    "\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Results for {input_image} - OpenMP VS Sequential\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Section 2: OpenMP vs Sequential\n",
    "        print(f\"Output file Name: {output_image_openmp}\")\n",
    "        print(f\"Output file Name: {output_image_sequential}\\n\")\n",
    "\n",
    "        print(f\"Sequential Execution Time   : {sequential_time:.4f} seconds\")\n",
    "        print(f\"Sequential Peak Memory Usage: {sequential_memory:.2f} MB\")\n",
    "        print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\\n\")\n",
    "\n",
    "        print(f\"OpenMP Execution Time   : {openmp_time:.4f} seconds\")\n",
    "        print(f\"OpenMP Peak Memory Usage: {openmp_memory:.2f} MB\")\n",
    "        print(f\"OpenMP Average CPU Usage: {average_openmp_cpu:.2f} %\\n\")\n",
    "\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Performance Evaluation - OpenMP VS Sequential\")\n",
    "        print(\"-\" * 80)\n",
    "        print(f\"Sequential Execution Time : {sequential_time:.4f}s\")\n",
    "        print(f\"OpenMP Execution Time     : {openmp_time:.4f}s\")\n",
    "        print(f\"Speedup                   : {sequential_time - openmp_time:+.4f}s\\n\")\n",
    "\n",
    "        print(f\"Sequential Memory Usage   : {sequential_memory:.2f} MB\")\n",
    "        print(f\"OpenMP Memory Usage       : {openmp_memory:.2f} MB\")\n",
    "        print(f\"Difference                : {sequential_memory - openmp_memory:+.2f} MB\\n\")\n",
    "\n",
    "        print(f\"Sequential Average CPU Usage: {average_sequential_cpu:.2f} %\")\n",
    "        print(f\"OpenMP Average CPU Usage    : {average_openmp_cpu:.2f} %\")\n",
    "        print(f\"Difference                  : {average_sequential_cpu - average_openmp_cpu:+.2f} %\\n\")\n",
    "\n",
    "            # Create bar chart for Sequential vs OpenMP execution time\n",
    "        fig_time_openmp = go.Figure()\n",
    "        fig_time_openmp.add_trace(go.Bar(x=[\"Sequential\", \"OpenMP\"], \n",
    "                                         y=[sequential_time, openmp_time], \n",
    "                                         name='Execution Time (s)', \n",
    "                                         marker_color=['blue', 'orange']))\n",
    "        fig_time_openmp.update_layout(\n",
    "            title=f'Sequential vs OpenMP Execution Time on {input_image}',\n",
    "            xaxis_title='Method',\n",
    "            yaxis_title='Time (seconds)',\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        fig_time_openmp.show()\n",
    "    \n",
    "        # Create bar chart for Sequential vs OpenMP memory usage\n",
    "        fig_memory_openmp = go.Figure()\n",
    "        fig_memory_openmp.add_trace(go.Bar(x=[\"Sequential\", \"OpenMP\"], \n",
    "                                           y=[sequential_memory, openmp_memory], \n",
    "                                           name='Memory Usage (MB)', \n",
    "                                           marker_color=['blue', 'orange']))\n",
    "        fig_memory_openmp.update_layout(\n",
    "            title=f'Sequential vs OpenMP Memory Usage on {input_image}',\n",
    "            xaxis_title='Method',\n",
    "            yaxis_title='Memory (MB)',\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        fig_memory_openmp.show()\n",
    "    \n",
    "        # Create bar chart for Sequential vs CUDA execution time\n",
    "        fig_time_cuda = go.Figure()\n",
    "        fig_time_cuda.add_trace(go.Bar(x=[\"Sequential\", \"CUDA\"], \n",
    "                                       y=[sequential_time, cuda_time], \n",
    "                                       name='Execution Time (s)', \n",
    "                                       marker_color=['blue', 'green']))\n",
    "        fig_time_cuda.update_layout(\n",
    "            title=f'Sequential vs CUDA Execution Time on {input_image}',\n",
    "            xaxis_title='Method',\n",
    "            yaxis_title='Time (seconds)',\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        fig_time_cuda.show()\n",
    "    \n",
    "        # Create bar chart for Sequential vs CUDA memory usage\n",
    "        fig_memory_cuda = go.Figure()\n",
    "        fig_memory_cuda.add_trace(go.Bar(x=[\"Sequential\", \"CUDA\"], \n",
    "                                         y=[sequential_memory, cuda_memory], \n",
    "                                         name='Memory Usage (MB)', \n",
    "                                         marker_color=['blue', 'green']))\n",
    "        fig_memory_cuda.update_layout(\n",
    "            title=f'Sequential vs CUDA Memory Usage on {input_image}',\n",
    "            xaxis_title='Method',\n",
    "            yaxis_title='Memory (MB)',\n",
    "            template='plotly_dark'\n",
    "        )\n",
    "        fig_memory_cuda.show()\n",
    "\n",
    "def main():\n",
    "    # Example input sets\n",
    "    input_sets = [\n",
    "        {'input_image': 'deer_360p.jpg', 'output_image_base': 'deer.jpg', 'scale_factor': 6},\n",
    "        {'input_image': 'flower_360p.jpg', 'output_image_base': 'flower.jpg', 'scale_factor': 6},\n",
    "        {'input_image': 'santa_360p.jpg', 'output_image_base': 'santa.jpg', 'scale_factor': 6},\n",
    "        {'input_image': 'flower_1k.jpg', 'output_image_base': 'flower.jpg', 'scale_factor': 1.3333},\n",
    "        {'input_image': 'santa_1k.jpg', 'output_image_base': 'santa.jpg', 'scale_factor': 1.3333},\n",
    "        {'input_image': 'deer_1k.jpg', 'output_image_base': 'deer.jpg', 'scale_factor': 1.3333},\n",
    "        {'input_image': 'deer_4k.jpg', 'output_image_base': 'deer.jpg', 'scale_factor': 0.5},\n",
    "        {'input_image': 'flower_4k.jpg', 'output_image_base': 'flower.jpg', 'scale_factor': 0.5},\n",
    "        {'input_image': 'santa_4k.jpg', 'output_image_base': 'santa.jpg', 'scale_factor': 0.5}\n",
    "\n",
    "    ]\n",
    "\n",
    "    run_multiple_inputs(input_sets)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e0d5-15ea-43a0-832d-a05096da5544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
